{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwriting Synthesis Model Fine-Tuning on Google Colab\n",
    "\n",
    "This notebook fine-tunes a pre-trained handwriting synthesis model using your personal handwriting data from HuggingFace.\n",
    "\n",
    "## Features:\n",
    "- Loads pre-trained model from existing checkpoints\n",
    "- Fine-tunes on your HuggingFace dataset (finnbusse/v3testing format)\n",
    "- tqdm progress bars for training visualization\n",
    "- Sample generation every 5-10 epochs with multiple visualization methods\n",
    "- ONNX model export\n",
    "- Automatic upload to HuggingFace Hub (finnbusse/handwriting-synthesis-models)\n",
    "- CUDA/T4 GPU optimized\n",
    "\n",
    "**Note:** Select GPU runtime: Runtime > Change runtime type > GPU (T4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/finnbusse/pytorch-handwriting-synthesis-toolkit.git\n",
    "%cd pytorch-handwriting-synthesis-toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (compatible with Google Colab Python 3.11+ and PyTorch 2.x)\n",
    "!pip install -q Pillow h5py svgwrite datasets tqdm huggingface_hub onnx onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from IPython.display import display, Image, clear_output, HTML\n",
    "from datasets import load_dataset\n",
    "from datetime import datetime\n",
    "import h5py\n",
    "import io\n",
    "import base64\n",
    "from PIL import Image as PILImage\n",
    "\n",
    "# Add the repository to the path\n",
    "sys.path.insert(0, os.getcwd())\n",
    "\n",
    "from handwriting_synthesis import data, models, utils, losses, metrics\n",
    "from handwriting_synthesis.data import Tokenizer\n",
    "from handwriting_synthesis.sampling import HandwritingSynthesizer\n",
    "from handwriting_synthesis.tasks import HandwritingSynthesisTask\n",
    "from handwriting_synthesis.optimizers import CustomRMSprop\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION - Fine-tuning settings\n",
    "# =============================================================================\n",
    "\n",
    "# HuggingFace Settings\n",
    "HUGGINGFACE_DATASET = \"finnbusse/v3testing\"  # Your handwriting dataset\n",
    "HUGGINGFACE_MODEL_REPO = \"finnbusse/handwriting-synthesis-models\"  # Where to upload models\n",
    "HF_TOKEN = \"\"  # Your HuggingFace token (set this for private repos and uploads)\n",
    "\n",
    "# Pre-trained model source (from this repo's checkpoints or HuggingFace)\n",
    "USE_PRETRAINED = True  # Set False to train from scratch\n",
    "PRETRAINED_CHECKPOINT = \"checkpoints/Epoch_50\"  # Local checkpoint path\n",
    "\n",
    "# Fine-tuning hyperparameters (optimized for small personal datasets)\n",
    "config = {\n",
    "    'batch_size': 8,              # Smaller batch for fine-tuning\n",
    "    'epochs': 100,                # Fine-tuning epochs\n",
    "    'learning_rate': 0.00005,     # Lower LR for fine-tuning (half of training LR)\n",
    "    'hidden_size': 400,           # Must match pre-trained model\n",
    "    'gradient_clip_output': 100,\n",
    "    'gradient_clip_lstm': 10,\n",
    "    'validation_split': 0.15,\n",
    "    'max_seq_length': 500,\n",
    "    'sample_interval': 5,         # Show samples every N epochs\n",
    "}\n",
    "\n",
    "# Directories\n",
    "MODEL_SAVE_DIR = 'finetuned_checkpoints'\n",
    "SAMPLES_DIR = 'finetuning_samples'\n",
    "ONNX_DIR = 'onnx_export'\n",
    "\n",
    "os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n",
    "os.makedirs(SAMPLES_DIR, exist_ok=True)\n",
    "os.makedirs(ONNX_DIR, exist_ok=True)\n",
    "\n",
    "# Generate unique model ID for this training run\n",
    "TRAINING_TIMESTAMP = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "MODEL_ID = f\"finetuned_{TRAINING_TIMESTAMP}\"\n",
    "\n",
    "print(f\"Model ID: {MODEL_ID}\")\n",
    "print(f\"Configuration:\")\n",
    "for key, value in config.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Dataset from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from HuggingFace\n",
    "print(f\"Loading dataset: {HUGGINGFACE_DATASET}\")\n",
    "try:\n",
    "    if HF_TOKEN:\n",
    "        dataset = load_dataset(HUGGINGFACE_DATASET, token=HF_TOKEN)\n",
    "    else:\n",
    "        dataset = load_dataset(HUGGINGFACE_DATASET)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading dataset: {e}\")\n",
    "    raise\n",
    "\n",
    "# Get the training split\n",
    "if 'train' in dataset:\n",
    "    raw_data = dataset['train']\n",
    "else:\n",
    "    split_name = list(dataset.keys())[0]\n",
    "    raw_data = dataset[split_name]\n",
    "\n",
    "print(f\"\\nTotal samples: {len(raw_data)}\")\n",
    "print(f\"\\nSample columns: {raw_data.column_names}\")\n",
    "if len(raw_data) > 0:\n",
    "    sample = raw_data[0]\n",
    "    print(f\"First sample text: '{sample.get('text', 'N/A')}'\")\n",
    "    print(f\"Stroke points: {len(sample.get('dx', []))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_training_data(raw_data, max_seq_length=500):\n",
    "    \"\"\"\n",
    "    Prepare training data from HuggingFace dataset.\n",
    "    The dataset format: dx, dy, eos lists (already in offset format)\n",
    "    \"\"\"\n",
    "    prepared_data = []\n",
    "    skipped = 0\n",
    "    \n",
    "    for item in tqdm(raw_data, desc=\"Converting data\"):\n",
    "        text = item.get('text', '')\n",
    "        dx = item.get('dx', [])\n",
    "        dy = item.get('dy', [])\n",
    "        eos = item.get('eos', [])\n",
    "        \n",
    "        if not text or not dx or not dy or not eos:\n",
    "            skipped += 1\n",
    "            continue\n",
    "        \n",
    "        min_len = min(len(dx), len(dy), len(eos))\n",
    "        if min_len == 0 or min_len > max_seq_length:\n",
    "            skipped += 1\n",
    "            continue\n",
    "        \n",
    "        # Combine into offset tuples (dx, dy, eos)\n",
    "        offsets = [(float(dx[i]), float(dy[i]), int(eos[i])) for i in range(min_len)]\n",
    "        \n",
    "        # Ensure last point has eos=1\n",
    "        if offsets:\n",
    "            last = offsets[-1]\n",
    "            offsets[-1] = (last[0], last[1], 1)\n",
    "        \n",
    "        prepared_data.append((offsets, text))\n",
    "    \n",
    "    if skipped > 0:\n",
    "        print(f\"Skipped {skipped} samples\")\n",
    "    \n",
    "    return prepared_data\n",
    "\n",
    "# Prepare the data\n",
    "print(\"Preparing training data...\")\n",
    "all_data = prepare_training_data(raw_data, config['max_seq_length'])\n",
    "print(f\"Prepared {len(all_data)} valid samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train/val\n",
    "random.seed(42)\n",
    "shuffled_data = all_data.copy()\n",
    "random.shuffle(shuffled_data)\n",
    "\n",
    "val_size = int(len(shuffled_data) * config['validation_split'])\n",
    "train_data = shuffled_data[:-val_size] if val_size > 0 else shuffled_data\n",
    "val_data = shuffled_data[-val_size:] if val_size > 0 else []\n",
    "\n",
    "print(f\"Training samples: {len(train_data)}\")\n",
    "print(f\"Validation samples: {len(val_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Build Charset and Create H5 Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build charset from training data\n",
    "def build_charset(data_list):\n",
    "    charset = set()\n",
    "    for _, text in data_list:\n",
    "        charset.update(set(text))\n",
    "    return ''.join(sorted(charset))\n",
    "\n",
    "charset = build_charset(train_data)\n",
    "print(f\"Charset ({len(charset)} characters): '{charset}'\")\n",
    "\n",
    "# Add newline as sentinel if not present\n",
    "if '\\n' not in charset:\n",
    "    charset = charset + '\\n'\n",
    "\n",
    "tokenizer = Tokenizer(charset)\n",
    "print(f\"Tokenizer size: {tokenizer.size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data to H5 format for compatibility with the training pipeline\n",
    "def save_data_to_h5(data_list, save_path, max_length):\n",
    "    \"\"\"Save prepared data to H5 format.\"\"\"\n",
    "    with h5py.File(save_path, 'w') as f:\n",
    "        dt = h5py.string_dtype(encoding='utf-8')\n",
    "        ds_sequences = f.create_dataset('sequences', (0, max_length, 3), maxshape=(None, max_length, 3))\n",
    "        ds_lengths = f.create_dataset('lengths', (0,), maxshape=(None,), dtype='i2')\n",
    "        ds_texts = f.create_dataset('texts', (0,), maxshape=(None,), dtype=dt)\n",
    "        ds_sequences.attrs['max_length'] = max_length\n",
    "        \n",
    "        for i, (points, text) in enumerate(tqdm(data_list, desc=\"Saving to H5\")):\n",
    "            a = np.array(points, dtype=np.float16)\n",
    "            unpadded_length = len(a)\n",
    "            padding_value = max_length - unpadded_length\n",
    "            a = np.pad(a, pad_width=[(0, padding_value), (0, 0)])\n",
    "            \n",
    "            ds_sequences.resize((i + 1, max_length, 3))\n",
    "            ds_sequences[i] = a\n",
    "            ds_lengths.resize((i + 1,))\n",
    "            ds_texts.resize((i + 1,))\n",
    "            ds_lengths[i] = unpadded_length\n",
    "            ds_texts[i] = text\n",
    "    \n",
    "    # Compute mu and std\n",
    "    with h5py.File(save_path, 'r') as f:\n",
    "        ds_lengths = f['lengths']\n",
    "        ds_sequences = f['sequences']\n",
    "        num_examples = len(ds_lengths)\n",
    "        \n",
    "        s = np.zeros(3, dtype=np.float32)\n",
    "        n = 0\n",
    "        for i in range(num_examples):\n",
    "            seq_len = ds_lengths[i]\n",
    "            seq = ds_sequences[i][:seq_len]\n",
    "            s += seq.sum(axis=0)\n",
    "            n += seq_len\n",
    "        mu = s / n if n > 0 else np.zeros(3)\n",
    "        mu[2] = 0.\n",
    "        \n",
    "        squared_sum = np.zeros(3, dtype=np.float32)\n",
    "        for i in range(num_examples):\n",
    "            seq_len = ds_lengths[i]\n",
    "            seq = ds_sequences[i][:seq_len]\n",
    "            squared_sum += ((seq - mu) ** 2).sum(axis=0)\n",
    "        std = np.sqrt(squared_sum / n) if n > 0 else np.ones(3)\n",
    "        std[2] = 1.\n",
    "    \n",
    "    with h5py.File(save_path, 'a') as f:\n",
    "        ds_sequences = f['sequences']\n",
    "        ds_sequences.attrs['mu'] = mu\n",
    "        ds_sequences.attrs['std'] = std\n",
    "    \n",
    "    return tuple(mu), tuple(std)\n",
    "\n",
    "# Get max sequence length\n",
    "dataset_max_length = max(len(pts) for pts, _ in all_data) if all_data else config['max_seq_length']\n",
    "dataset_max_length = min(dataset_max_length, config['max_seq_length'])\n",
    "print(f\"Max sequence length: {dataset_max_length}\")\n",
    "\n",
    "# Save train and val data\n",
    "train_path = 'finetune_train.h5'\n",
    "val_path = 'finetune_val.h5'\n",
    "\n",
    "mu, std = save_data_to_h5(train_data, train_path, dataset_max_length)\n",
    "if val_data:\n",
    "    save_data_to_h5(val_data, val_path, dataset_max_length)\n",
    "else:\n",
    "    # Use train data for validation if no val data\n",
    "    save_data_to_h5(train_data[:max(1, len(train_data)//10)], val_path, dataset_max_length)\n",
    "\n",
    "print(f\"\\nData statistics:\")\n",
    "print(f\"  mu: {mu}\")\n",
    "print(f\"  std: {std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Load Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load or create model\n",
    "if USE_PRETRAINED and os.path.exists(PRETRAINED_CHECKPOINT):\n",
    "    print(f\"\\nLoading pre-trained model from: {PRETRAINED_CHECKPOINT}\")\n",
    "    synthesizer = HandwritingSynthesizer.load(PRETRAINED_CHECKPOINT, device, bias=0)\n",
    "    model = synthesizer.model\n",
    "    pretrained_charset = synthesizer.tokenizer.charset\n",
    "    \n",
    "    # Check charset compatibility\n",
    "    print(f\"Pre-trained charset: '{pretrained_charset}'\")\n",
    "    print(f\"Dataset charset: '{charset}'\")\n",
    "    \n",
    "    # Use the larger charset (union of both)\n",
    "    combined_charset = ''.join(sorted(set(pretrained_charset) | set(charset)))\n",
    "    if '\\n' not in combined_charset:\n",
    "        combined_charset += '\\n'\n",
    "    \n",
    "    # If charsets differ, we need to create a new model with the combined charset\n",
    "    if combined_charset != pretrained_charset:\n",
    "        print(f\"\\nExpanding charset to: '{combined_charset}'\")\n",
    "        new_alphabet_size = len(combined_charset) + 1  # +1 for padding\n",
    "        \n",
    "        # Create new model with expanded alphabet\n",
    "        new_model = models.SynthesisNetwork.get_default_model(new_alphabet_size, device)\n",
    "        new_model = new_model.to(device)\n",
    "        \n",
    "        # Transfer compatible weights\n",
    "        old_state = model.state_dict()\n",
    "        new_state = new_model.state_dict()\n",
    "        \n",
    "        for name, param in old_state.items():\n",
    "            if name in new_state:\n",
    "                if param.shape == new_state[name].shape:\n",
    "                    new_state[name] = param\n",
    "                else:\n",
    "                    # Handle dimension mismatch (alphabet size change)\n",
    "                    print(f\"  Skipping {name} due to shape mismatch: {param.shape} vs {new_state[name].shape}\")\n",
    "        \n",
    "        new_model.load_state_dict(new_state)\n",
    "        model = new_model\n",
    "        tokenizer = Tokenizer(combined_charset)\n",
    "    else:\n",
    "        tokenizer = Tokenizer(combined_charset)\n",
    "    \n",
    "    print(f\"\\nModel loaded successfully!\")\n",
    "    print(f\"Final alphabet size: {tokenizer.size}\")\n",
    "else:\n",
    "    print(\"\\nCreating new model (no pre-trained weights)\")\n",
    "    alphabet_size = tokenizer.size\n",
    "    model = models.SynthesisNetwork.get_default_model(alphabet_size, device)\n",
    "    model = model.to(device)\n",
    "\n",
    "# Create synthesizer for saving\n",
    "mu_tensor = torch.tensor(mu, dtype=torch.float32)\n",
    "std_tensor = torch.tensor(std, dtype=torch.float32)\n",
    "synthesizer = HandwritingSynthesizer(model, mu_tensor, std_tensor, tokenizer.charset, num_steps=dataset_max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    \"\"\"Custom collate function for DataLoader.\"\"\"\n",
    "    x = [item[0] for item in batch]\n",
    "    y = [item[1] for item in batch]\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def compute_loss(model, batch, tokenizer, device):\n",
    "    \"\"\"Compute loss for a batch.\"\"\"\n",
    "    points, transcriptions = batch\n",
    "    ground_true = utils.PaddedSequencesBatch(points, device=device)\n",
    "    \n",
    "    batch_size, steps, input_dim = ground_true.tensor.shape\n",
    "    prefix = torch.zeros(batch_size, 1, input_dim, device=device)\n",
    "    x = torch.cat([prefix, ground_true.tensor[:, :-1]], dim=1)\n",
    "    \n",
    "    c = data.transcriptions_to_tensor(tokenizer, transcriptions).to(device)\n",
    "    \n",
    "    mixtures, eos_hat = model(x, c)\n",
    "    loss = losses.nll_loss(mixtures, eos_hat, ground_true)\n",
    "    \n",
    "    return (mixtures, eos_hat), loss\n",
    "\n",
    "\n",
    "def generate_sample(model, tokenizer, mu, std, text, device, max_steps=500):\n",
    "    \"\"\"Generate a handwriting sample.\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        sentinel = '\\n'\n",
    "        text_with_sentinel = text + sentinel\n",
    "        c = data.transcriptions_to_tensor(tokenizer, [text_with_sentinel]).to(device)\n",
    "        sample = model.sample_means(context=c, steps=max_steps, stochastic=True)\n",
    "        sample = sample.cpu() * torch.tensor(std) + torch.tensor(mu)\n",
    "    model.train()\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_sample_multiple(sample, text, epoch, sample_idx, save_dir):\n",
    "    \"\"\"\n",
    "    Visualize sample using multiple methods for robust preview.\n",
    "    Uses PIL, matplotlib, and SVG for redundancy.\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    if sample is None or len(sample) == 0:\n",
    "        print(f\"  '{text}' - [Empty sample]\")\n",
    "        return\n",
    "    \n",
    "    sample_np = sample.cpu().numpy() if hasattr(sample, 'cpu') else np.array(sample)\n",
    "    x_range = sample_np[:, 0].max() - sample_np[:, 0].min()\n",
    "    y_range = sample_np[:, 1].max() - sample_np[:, 1].min()\n",
    "    \n",
    "    if abs(x_range) > 5000 or abs(y_range) > 5000:\n",
    "        print(f\"  '{text}' - [Wild coordinates, model still learning]\")\n",
    "        return\n",
    "    \n",
    "    # Method 1: PIL Image (primary)\n",
    "    try:\n",
    "        png_path = os.path.join(save_dir, f'epoch_{epoch}_sample_{sample_idx}.png')\n",
    "        utils.visualize_strokes(sample, png_path, lines=True, thickness=8)\n",
    "        if os.path.exists(png_path) and os.path.getsize(png_path) > 0:\n",
    "            display(Image(filename=png_path))\n",
    "            print(f\"  '{text}'\")\n",
    "            return\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    \n",
    "    # Method 2: Matplotlib fallback\n",
    "    try:\n",
    "        fig, ax = plt.subplots(figsize=(12, 4))\n",
    "        ax.set_facecolor('white')\n",
    "        \n",
    "        # Convert to absolute coordinates\n",
    "        x, y = 0, 0\n",
    "        positions = []\n",
    "        for dx, dy, eos in sample_np:\n",
    "            x += dx\n",
    "            y += dy\n",
    "            positions.append((x, y, eos))\n",
    "        \n",
    "        # Draw strokes\n",
    "        current_stroke_x, current_stroke_y = [], []\n",
    "        for px, py, eos in positions:\n",
    "            current_stroke_x.append(px)\n",
    "            current_stroke_y.append(py)\n",
    "            if eos > 0.5:\n",
    "                ax.plot(current_stroke_x, current_stroke_y, 'k-', linewidth=2)\n",
    "                current_stroke_x, current_stroke_y = [], []\n",
    "        if current_stroke_x:\n",
    "            ax.plot(current_stroke_x, current_stroke_y, 'k-', linewidth=2)\n",
    "        \n",
    "        ax.invert_yaxis()\n",
    "        ax.set_aspect('equal')\n",
    "        ax.axis('off')\n",
    "        ax.set_title(f\"'{text}'\")\n",
    "        \n",
    "        plt_path = os.path.join(save_dir, f'epoch_{epoch}_sample_{sample_idx}_mpl.png')\n",
    "        plt.savefig(plt_path, dpi=100, bbox_inches='tight', facecolor='white')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        print(f\"  '{text}' (matplotlib)\")\n",
    "    except Exception as e:\n",
    "        print(f\"  '{text}' - [Visualization failed: {str(e)[:50]}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Fine-Tuning Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup optimizer with lower learning rate for fine-tuning\n",
    "optimizer = CustomRMSprop(\n",
    "    model.parameters(),\n",
    "    lr=config['learning_rate'],\n",
    "    alpha=0.95,\n",
    "    eps=1e-4,\n",
    "    momentum=0.9,\n",
    "    centered=True\n",
    ")\n",
    "\n",
    "clip_output = config['gradient_clip_output']\n",
    "clip_lstm = config['gradient_clip_lstm']\n",
    "\n",
    "print(f\"Optimizer: CustomRMSprop, LR: {config['learning_rate']}\")\n",
    "print(f\"Gradient clipping: output={clip_output}, lstm={clip_lstm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Starting Fine-Tuning\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "EPOCHS = config['epochs']\n",
    "BATCH_SIZE = config['batch_size']\n",
    "SAMPLE_INTERVAL = config['sample_interval']\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "best_val_loss = float('inf')\n",
    "best_model_dir = os.path.join(MODEL_SAVE_DIR, 'best_model')\n",
    "\n",
    "# Open datasets\n",
    "train_dataset = data.NormalizedDataset(train_path, mu, std)\n",
    "val_dataset = data.NormalizedDataset(val_path, mu, std)\n",
    "\n",
    "# Sample texts for visualization\n",
    "sample_texts = []\n",
    "for i in range(min(3, len(val_dataset))):\n",
    "    _, text = val_dataset[i]\n",
    "    sample_texts.append(text)\n",
    "print(f\"Sample texts: {sample_texts}\")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "num_train_batches = len(train_loader)\n",
    "num_val_batches = len(val_loader)\n",
    "\n",
    "print(f\"Training batches: {num_train_batches}\")\n",
    "print(f\"Validation batches: {num_val_batches}\")\n",
    "\n",
    "try:\n",
    "    epoch_pbar = tqdm(range(1, EPOCHS + 1), desc=\"Fine-tuning\", unit=\"epoch\")\n",
    "    \n",
    "    for epoch in epoch_pbar:\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        epoch_train_loss = 0.0\n",
    "        \n",
    "        batch_pbar = tqdm(train_loader, desc=f\"Epoch {epoch}/{EPOCHS}\", leave=False, unit=\"batch\")\n",
    "        for batch_idx, batch in enumerate(batch_pbar):\n",
    "            optimizer.zero_grad()\n",
    "            y_hat, loss = compute_loss(model, batch, tokenizer, device)\n",
    "            loss.backward()\n",
    "            model.clip_gradients(output_clip_value=clip_output, lstm_clip_value=clip_lstm)\n",
    "            optimizer.step()\n",
    "            epoch_train_loss += loss.item()\n",
    "            batch_pbar.set_postfix({'loss': f'{loss.item():.2f}'})\n",
    "        \n",
    "        avg_train_loss = epoch_train_loss / max(1, num_train_batches)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        epoch_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                _, loss = compute_loss(model, batch, tokenizer, device)\n",
    "                epoch_val_loss += loss.item()\n",
    "        \n",
    "        avg_val_loss = epoch_val_loss / max(1, num_val_batches)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        epoch_pbar.set_postfix({'train': f'{avg_train_loss:.2f}', 'val': f'{avg_val_loss:.2f}'})\n",
    "        \n",
    "        # Save best model\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            synthesizer.save(best_model_dir)\n",
    "        \n",
    "        # Generate samples every SAMPLE_INTERVAL epochs\n",
    "        if epoch % SAMPLE_INTERVAL == 0:\n",
    "            print(f\"\\n\\n{'='*60}\")\n",
    "            print(f\"Epoch {epoch} - Samples (Train: {avg_train_loss:.2f}, Val: {avg_val_loss:.2f})\")\n",
    "            print(f\"{'='*60}\")\n",
    "            \n",
    "            for i, text in enumerate(sample_texts[:2]):\n",
    "                sample = generate_sample(model, tokenizer, mu, std, text, device, dataset_max_length)\n",
    "                visualize_sample_multiple(sample, text, epoch, i, SAMPLES_DIR)\n",
    "            print()\n",
    "        \n",
    "        # Save checkpoint every 10 epochs\n",
    "        if epoch % 10 == 0:\n",
    "            checkpoint_dir = os.path.join(MODEL_SAVE_DIR, f'Epoch_{epoch}')\n",
    "            synthesizer.save(checkpoint_dir)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Fine-Tuning Complete!\")\n",
    "    print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "finally:\n",
    "    train_dataset.close()\n",
    "    val_dataset.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Training Loss', color='blue', alpha=0.8)\n",
    "plt.plot(val_losses, label='Validation Loss', color='orange', alpha=0.8)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (nats)')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "window = min(10, len(train_losses) // 4) if len(train_losses) > 4 else 1\n",
    "if window > 1:\n",
    "    train_smooth = np.convolve(train_losses, np.ones(window)/window, mode='valid')\n",
    "    val_smooth = np.convolve(val_losses, np.ones(window)/window, mode='valid')\n",
    "    plt.plot(range(window-1, len(train_losses)), train_smooth, label='Training (smoothed)')\n",
    "    plt.plot(range(window-1, len(val_losses)), val_smooth, label='Validation (smoothed)')\n",
    "else:\n",
    "    plt.plot(train_losses, label='Training')\n",
    "    plt.plot(val_losses, label='Validation')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (nats)')\n",
    "plt.title('Smoothed Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('finetuning_history.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Final Train Loss: {train_losses[-1]:.4f}\")\n",
    "print(f\"Final Val Loss: {val_losses[-1]:.4f}\")\n",
    "print(f\"Best Val Loss: {best_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Generate Final Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "best_synthesizer = HandwritingSynthesizer.load(best_model_dir, device, bias=1.0)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Final Generated Samples (Best Model)\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "val_dataset = data.NormalizedDataset(val_path, mu, std)\n",
    "\n",
    "for i in range(min(5, len(val_dataset))):\n",
    "    _, text = val_dataset[i]\n",
    "    sample = generate_sample(best_synthesizer.model, tokenizer, mu, std, text, device, dataset_max_length)\n",
    "    visualize_sample_multiple(sample, text, 'final', i, SAMPLES_DIR)\n",
    "\n",
    "val_dataset.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Export to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Exporting model to ONNX format...\")\n",
    "\n",
    "# Import ONNX export model\n",
    "import onnx_models\n",
    "\n",
    "# Create ONNX-compatible model\n",
    "onnx_model = onnx_models.SynthesisNetwork.get_default_model(tokenizer.size, torch.device('cpu'), bias=0)\n",
    "\n",
    "# Load weights from best model\n",
    "best_model_path = os.path.join(best_model_dir, 'model.pt')\n",
    "state_dict = torch.load(best_model_path, map_location='cpu')\n",
    "onnx_model.load_state_dict(state_dict)\n",
    "onnx_model.eval()\n",
    "\n",
    "# Create dummy inputs for export\n",
    "alphabet_size = tokenizer.size\n",
    "x = torch.randn(1, 1, 3, dtype=torch.float32)\n",
    "c = torch.randn(1, 1, alphabet_size, dtype=torch.float32)\n",
    "w = torch.randn(1, 1, alphabet_size, dtype=torch.float32)\n",
    "k = torch.randn(1, 10, dtype=torch.float32)\n",
    "h1 = torch.randn(1, 400, dtype=torch.float32)\n",
    "c1 = torch.randn(1, 400, dtype=torch.float32)\n",
    "h2 = torch.randn(1, 400, dtype=torch.float32)\n",
    "c2 = torch.randn(1, 400, dtype=torch.float32)\n",
    "h3 = torch.randn(1, 400, dtype=torch.float32)\n",
    "c3 = torch.randn(1, 400, dtype=torch.float32)\n",
    "bias = torch.randn(1, dtype=torch.float32)\n",
    "\n",
    "onnx_path = os.path.join(ONNX_DIR, f'{MODEL_ID}.onnx')\n",
    "\n",
    "torch.onnx.export(\n",
    "    onnx_model,\n",
    "    (x, c, w, k, h1, c1, h2, c2, h3, c3, bias),\n",
    "    onnx_path,\n",
    "    verbose=False,\n",
    "    opset_version=11,\n",
    "    input_names=['x', 'c', 'w', 'k', 'h1', 'c1', 'h2', 'c2', 'h3', 'c3', 'bias'],\n",
    "    output_names=['pi', 'mu', 'sd', 'ro', 'eos', 'w_out', 'k_out', 'h1_out', 'c1_out', 'h2_out', 'c2_out', 'h3_out', 'c3_out', 'phi'],\n",
    "    dynamic_axes={'c': {1: 'sequence'}, 'phi': {2: 'string_length'}}\n",
    ")\n",
    "\n",
    "print(f\"ONNX model exported to: {onnx_path}\")\n",
    "\n",
    "# Verify ONNX model\n",
    "import onnx\n",
    "onnx_model_check = onnx.load(onnx_path)\n",
    "onnx.checker.check_model(onnx_model_check)\n",
    "print(\"ONNX model verification: PASSED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Upload to HuggingFace Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi, login\n",
    "import shutil\n",
    "\n",
    "# Login to HuggingFace\n",
    "if HF_TOKEN:\n",
    "    login(token=HF_TOKEN)\n",
    "    print(\"Logged in to HuggingFace Hub\")\n",
    "else:\n",
    "    print(\"No HF_TOKEN provided. Please set HF_TOKEN to upload models.\")\n",
    "    print(\"You can still download the model files manually.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_to_huggingface(model_dir, onnx_path, repo_id, model_id, epoch_num='best'):\n",
    "    \"\"\"\n",
    "    Upload model files to HuggingFace Hub.\n",
    "    Structure: repo_id/datetime/model_id/epoch_number/\n",
    "    \"\"\"\n",
    "    if not HF_TOKEN:\n",
    "        print(\"Skipping upload - no HF_TOKEN provided\")\n",
    "        return None\n",
    "    \n",
    "    api = HfApi()\n",
    "    \n",
    "    # Create path in repo\n",
    "    timestamp = TRAINING_TIMESTAMP\n",
    "    repo_path = f\"{timestamp}/{model_id}/epoch_{epoch_num}\"\n",
    "    \n",
    "    try:\n",
    "        # Check if repo exists, create if not\n",
    "        try:\n",
    "            api.repo_info(repo_id=repo_id, repo_type=\"model\")\n",
    "        except Exception:\n",
    "            print(f\"Creating repository: {repo_id}\")\n",
    "            api.create_repo(repo_id=repo_id, repo_type=\"model\", exist_ok=True)\n",
    "        \n",
    "        # Upload model files\n",
    "        print(f\"Uploading to {repo_id}/{repo_path}...\")\n",
    "        \n",
    "        # Upload model.pt\n",
    "        model_pt = os.path.join(model_dir, 'model.pt')\n",
    "        if os.path.exists(model_pt):\n",
    "            api.upload_file(\n",
    "                path_or_fileobj=model_pt,\n",
    "                path_in_repo=f\"{repo_path}/model.pt\",\n",
    "                repo_id=repo_id,\n",
    "                repo_type=\"model\"\n",
    "            )\n",
    "            print(f\"  Uploaded model.pt\")\n",
    "        \n",
    "        # Upload meta.json\n",
    "        meta_json = os.path.join(model_dir, 'meta.json')\n",
    "        if os.path.exists(meta_json):\n",
    "            api.upload_file(\n",
    "                path_or_fileobj=meta_json,\n",
    "                path_in_repo=f\"{repo_path}/meta.json\",\n",
    "                repo_id=repo_id,\n",
    "                repo_type=\"model\"\n",
    "            )\n",
    "            print(f\"  Uploaded meta.json\")\n",
    "        \n",
    "        # Upload ONNX model\n",
    "        if os.path.exists(onnx_path):\n",
    "            onnx_filename = os.path.basename(onnx_path)\n",
    "            api.upload_file(\n",
    "                path_or_fileobj=onnx_path,\n",
    "                path_in_repo=f\"{repo_path}/{onnx_filename}\",\n",
    "                repo_id=repo_id,\n",
    "                repo_type=\"model\"\n",
    "            )\n",
    "            print(f\"  Uploaded {onnx_filename}\")\n",
    "        \n",
    "        # Create and upload config\n",
    "        config_data = {\n",
    "            'model_id': model_id,\n",
    "            'timestamp': timestamp,\n",
    "            'epoch': epoch_num,\n",
    "            'charset': tokenizer.charset,\n",
    "            'mu': list(mu),\n",
    "            'std': list(std),\n",
    "            'config': config\n",
    "        }\n",
    "        config_path = '/tmp/training_config.json'\n",
    "        with open(config_path, 'w') as f:\n",
    "            json.dump(config_data, f, indent=2)\n",
    "        \n",
    "        api.upload_file(\n",
    "            path_or_fileobj=config_path,\n",
    "            path_in_repo=f\"{repo_path}/training_config.json\",\n",
    "            repo_id=repo_id,\n",
    "            repo_type=\"model\"\n",
    "        )\n",
    "        print(f\"  Uploaded training_config.json\")\n",
    "        \n",
    "        print(f\"\\nUpload complete! View at: https://huggingface.co/{repo_id}/tree/main/{repo_path}\")\n",
    "        return f\"{repo_id}/{repo_path}\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Upload failed: {e}\")\n",
    "        return None\n",
    "\n",
    "# Upload best model\n",
    "upload_to_huggingface(best_model_dir, onnx_path, HUGGINGFACE_MODEL_REPO, MODEL_ID, 'best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Download Model Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create zip archive for download\n",
    "import shutil\n",
    "\n",
    "# Create export directory with all files\n",
    "export_dir = f'export_{MODEL_ID}'\n",
    "os.makedirs(export_dir, exist_ok=True)\n",
    "\n",
    "# Copy files\n",
    "if os.path.exists(best_model_dir):\n",
    "    shutil.copytree(best_model_dir, os.path.join(export_dir, 'pytorch_model'), dirs_exist_ok=True)\n",
    "if os.path.exists(onnx_path):\n",
    "    shutil.copy(onnx_path, export_dir)\n",
    "\n",
    "# Save training info\n",
    "training_info = {\n",
    "    'model_id': MODEL_ID,\n",
    "    'timestamp': TRAINING_TIMESTAMP,\n",
    "    'dataset': HUGGINGFACE_DATASET,\n",
    "    'config': config,\n",
    "    'final_train_loss': train_losses[-1] if train_losses else None,\n",
    "    'final_val_loss': val_losses[-1] if val_losses else None,\n",
    "    'best_val_loss': best_val_loss,\n",
    "    'charset': tokenizer.charset,\n",
    "    'mu': list(mu),\n",
    "    'std': list(std)\n",
    "}\n",
    "with open(os.path.join(export_dir, 'training_info.json'), 'w') as f:\n",
    "    json.dump(training_info, f, indent=2)\n",
    "\n",
    "# Create zip\n",
    "shutil.make_archive(f'handwriting_model_{MODEL_ID}', 'zip', export_dir)\n",
    "\n",
    "print(f\"\\nModel files ready for download:\")\n",
    "print(f\"  handwriting_model_{MODEL_ID}.zip\")\n",
    "print(f\"\\nContents:\")\n",
    "for root, dirs, files in os.walk(export_dir):\n",
    "    level = root.replace(export_dir, '').count(os.sep)\n",
    "    indent = '  ' * level\n",
    "    print(f\"{indent}{os.path.basename(root)}/\")\n",
    "    for file in files:\n",
    "        print(f\"{indent}  {file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download link for Colab\n",
    "try:\n",
    "    from google.colab import files\n",
    "    files.download(f'handwriting_model_{MODEL_ID}.zip')\n",
    "except ImportError:\n",
    "    print(\"Not running in Colab - file saved locally\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Test Your Fine-Tuned Model\n",
    "\n",
    "Enter custom text to generate handwriting samples with your fine-tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive testing\n",
    "test_texts = [\n",
    "    \"Hallo Welt\",\n",
    "    \"Das ist meine Handschrift\",\n",
    "    \"Test\"\n",
    "]\n",
    "\n",
    "print(\"Generating samples with fine-tuned model:\\n\")\n",
    "\n",
    "for i, text in enumerate(test_texts):\n",
    "    sample = generate_sample(best_synthesizer.model, tokenizer, mu, std, text, device, dataset_max_length)\n",
    "    visualize_sample_multiple(sample, text, 'test', i, SAMPLES_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "This notebook:\n",
    "1. \u2705 Loaded your handwriting data from HuggingFace\n",
    "2. \u2705 Fine-tuned a pre-trained model on your personal handwriting\n",
    "3. \u2705 Generated preview samples every 5 epochs\n",
    "4. \u2705 Exported the model to ONNX format\n",
    "5. \u2705 Uploaded to HuggingFace Hub (if token provided)\n",
    "\n",
    "Your model files are available for download above!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}