{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwriting Synthesis Model Training on Google Colab\n",
    "\n",
    "This notebook trains a handwriting synthesis model using the `finnbusse/v3testing` dataset from Hugging Face.\n",
    "\n",
    "## Features:\n",
    "- Loads stroke data from HuggingFace Parquet format\n",
    "- Optimized hyperparameters for different dataset sizes (565, 750, 1000, 1250, 1500, 1750, 2000 words)\n",
    "- tqdm progress bars for training visualization\n",
    "- Sample generation every 10 epochs\n",
    "- Training graphs and model saving at the end\n",
    "\n",
    "**Note:** Make sure to select a GPU runtime: Runtime > Change runtime type > GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/finnbusse/pytorch-handwriting-synthesis-toolkit.git\n",
    "%cd pytorch-handwriting-synthesis-toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q Pillow<10 numpy<2 torch<2 matplotlib<4 torchvision<1 requests<3 h5py<4 svgwrite<2\n",
    "!pip install -q datasets tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from IPython.display import display, Image, clear_output\n",
    "from datasets import load_dataset\n",
    "import h5py\n",
    "\n",
    "# Add the repository to the path\n",
    "sys.path.insert(0, os.getcwd())\n",
    "\n",
    "from handwriting_synthesis import data, models, utils, losses, metrics\n",
    "from handwriting_synthesis.data import Tokenizer\n",
    "from handwriting_synthesis.sampling import HandwritingSynthesizer\n",
    "from handwriting_synthesis.tasks import HandwritingSynthesisTask\n",
    "from handwriting_synthesis.optimizers import CustomRMSprop\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "\n",
    "Select your dataset size and corresponding optimized hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION - Optimized hyperparameters for different dataset sizes\n",
    "# =============================================================================\n",
    "\n",
    "# Dataset settings\n",
    "HUGGINGFACE_DATASET = \"finnbusse/v3testing\"\n",
    "\n",
    "# Select your dataset size (approximate number of words)\n",
    "# Options: 565, 750, 1000, 1250, 1500, 1750, 2000\n",
    "DATASET_SIZE = 565  # Change this to match your dataset size\n",
    "\n",
    "# Optimized hyperparameters for each dataset size\n",
    "# These are carefully tuned for handwriting synthesis on small-to-medium datasets\n",
    "HYPERPARAMETERS = {\n",
    "    565: {\n",
    "        'batch_size': 8,           # Small batch for small dataset\n",
    "        'epochs': 200,             # More epochs for small dataset\n",
    "        'learning_rate': 0.0001,   # Standard LR\n",
    "        'hidden_size': 400,        # Standard hidden size\n",
    "        'gradient_clip_output': 100,\n",
    "        'gradient_clip_lstm': 10,\n",
    "        'validation_split': 0.15,  # 15% for validation\n",
    "        'max_seq_length': 500,     # Max points per stroke sequence\n",
    "        'sample_interval': 10,     # Show sample every N epochs\n",
    "    },\n",
    "    750: {\n",
    "        'batch_size': 12,\n",
    "        'epochs': 180,\n",
    "        'learning_rate': 0.0001,\n",
    "        'hidden_size': 400,\n",
    "        'gradient_clip_output': 100,\n",
    "        'gradient_clip_lstm': 10,\n",
    "        'validation_split': 0.15,\n",
    "        'max_seq_length': 500,\n",
    "        'sample_interval': 10,\n",
    "    },\n",
    "    1000: {\n",
    "        'batch_size': 16,\n",
    "        'epochs': 150,\n",
    "        'learning_rate': 0.0001,\n",
    "        'hidden_size': 400,\n",
    "        'gradient_clip_output': 100,\n",
    "        'gradient_clip_lstm': 10,\n",
    "        'validation_split': 0.12,\n",
    "        'max_seq_length': 500,\n",
    "        'sample_interval': 10,\n",
    "    },\n",
    "    1250: {\n",
    "        'batch_size': 20,\n",
    "        'epochs': 130,\n",
    "        'learning_rate': 0.0001,\n",
    "        'hidden_size': 400,\n",
    "        'gradient_clip_output': 100,\n",
    "        'gradient_clip_lstm': 10,\n",
    "        'validation_split': 0.12,\n",
    "        'max_seq_length': 500,\n",
    "        'sample_interval': 10,\n",
    "    },\n",
    "    1500: {\n",
    "        'batch_size': 24,\n",
    "        'epochs': 120,\n",
    "        'learning_rate': 0.0001,\n",
    "        'hidden_size': 400,\n",
    "        'gradient_clip_output': 100,\n",
    "        'gradient_clip_lstm': 10,\n",
    "        'validation_split': 0.10,\n",
    "        'max_seq_length': 500,\n",
    "        'sample_interval': 10,\n",
    "    },\n",
    "    1750: {\n",
    "        'batch_size': 28,\n",
    "        'epochs': 110,\n",
    "        'learning_rate': 0.0001,\n",
    "        'hidden_size': 400,\n",
    "        'gradient_clip_output': 100,\n",
    "        'gradient_clip_lstm': 10,\n",
    "        'validation_split': 0.10,\n",
    "        'max_seq_length': 500,\n",
    "        'sample_interval': 10,\n",
    "    },\n",
    "    2000: {\n",
    "        'batch_size': 32,\n",
    "        'epochs': 100,\n",
    "        'learning_rate': 0.0001,\n",
    "        'hidden_size': 400,\n",
    "        'gradient_clip_output': 100,\n",
    "        'gradient_clip_lstm': 10,\n",
    "        'validation_split': 0.10,\n",
    "        'max_seq_length': 500,\n",
    "        'sample_interval': 10,\n",
    "    },\n",
    "}\n",
    "\n",
    "# Get hyperparameters for selected dataset size (use closest match)\n",
    "available_sizes = sorted(HYPERPARAMETERS.keys())\n",
    "selected_size = min(available_sizes, key=lambda x: abs(x - DATASET_SIZE))\n",
    "config = HYPERPARAMETERS[selected_size]\n",
    "\n",
    "print(f\"Selected configuration for ~{selected_size} words:\")\n",
    "for key, value in config.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Dataset from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from HuggingFace\n",
    "print(f\"Loading dataset: {HUGGINGFACE_DATASET}\")\n",
    "try:\n",
    "    dataset = load_dataset(HUGGINGFACE_DATASET)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading dataset: {e}\")\n",
    "    print(\"\\nPossible causes:\")\n",
    "    print(\"  - Dataset not found or requires authentication\")\n",
    "    print(\"  - Network connectivity issues\")\n",
    "    print(\"  - Invalid dataset name\")\n",
    "    print(\"\\nPlease verify the dataset name and try again.\")\n",
    "    raise\n",
    "\n",
    "# Display dataset info\n",
    "print(f\"\\nDataset structure:\")\n",
    "print(dataset)\n",
    "\n",
    "# Get the training split (or the main split if no train split exists)\n",
    "if 'train' in dataset:\n",
    "    raw_data = dataset['train']\n",
    "else:\n",
    "    # Use the first available split\n",
    "    split_name = list(dataset.keys())[0]\n",
    "    raw_data = dataset[split_name]\n",
    "\n",
    "print(f\"\\nTotal samples: {len(raw_data)}\")\n",
    "print(f\"\\nSample data structure (first item):\")\n",
    "sample = raw_data[0]\n",
    "for key in sample.keys():\n",
    "    value = sample[key]\n",
    "    if isinstance(value, (list, dict)):\n",
    "        print(f\"  {key}: {type(value).__name__} (length: {len(value) if hasattr(value, '__len__') else 'N/A'})\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Conversion and Preprocessing\n",
    "\n",
    "Convert the HuggingFace stroke format to the format expected by the training pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_hf_strokes_to_training_format(strokes, canvas_width=None, canvas_height=None, use_normalized=False):\n",
    "    \"\"\"\n",
    "    Convert HuggingFace stroke format to the format expected by the training pipeline.\n",
    "    \n",
    "    The finnbusse/v3testing dataset format (per stroke):\n",
    "      - List of points with: x, y (raw pixels), xn, yn (normalized 0-1), t (time), p (pressure), tiltX, tiltY\n",
    "    \n",
    "    Training pipeline format:\n",
    "      - List of strokes, each stroke is a list of (x, y) tuples\n",
    "      - Coordinates should be in a reasonable pixel range\n",
    "    \n",
    "    Args:\n",
    "        strokes: List of strokes from the HuggingFace dataset\n",
    "        canvas_width: Canvas width for scaling normalized coordinates (default: 400)\n",
    "        canvas_height: Canvas height for scaling normalized coordinates (default: 200)\n",
    "        use_normalized: If True, use normalized coords (xn, yn) and scale them; if False, use raw (x, y)\n",
    "    \n",
    "    Returns:\n",
    "        List of strokes in the format expected by the training pipeline\n",
    "    \"\"\"\n",
    "    converted_strokes = []\n",
    "    \n",
    "    # Default scaling factors for normalized coordinates\n",
    "    scale_x = canvas_width if canvas_width else 400\n",
    "    scale_y = canvas_height if canvas_height else 200\n",
    "    \n",
    "    for stroke in strokes:\n",
    "        if not stroke:  # Skip empty strokes\n",
    "            continue\n",
    "            \n",
    "        converted_stroke = []\n",
    "        for point in stroke:\n",
    "            x, y = None, None\n",
    "            \n",
    "            if isinstance(point, dict):\n",
    "                # Dictionary format from the dataset\n",
    "                if use_normalized and 'xn' in point and 'yn' in point:\n",
    "                    # Use normalized coordinates and scale them\n",
    "                    x = point['xn'] * scale_x\n",
    "                    y = point['yn'] * scale_y\n",
    "                elif 'x' in point and 'y' in point:\n",
    "                    # Use raw pixel coordinates (preferred)\n",
    "                    x = point['x']\n",
    "                    y = point['y']\n",
    "                elif 'xn' in point and 'yn' in point:\n",
    "                    # Fallback to normalized if raw not available\n",
    "                    x = point['xn'] * scale_x\n",
    "                    y = point['yn'] * scale_y\n",
    "            elif isinstance(point, (list, tuple)):\n",
    "                # List/tuple format - assume [x, y, ...]\n",
    "                if len(point) >= 2:\n",
    "                    x, y = point[0], point[1]\n",
    "            \n",
    "            if x is not None and y is not None:\n",
    "                converted_stroke.append((float(x), float(y)))\n",
    "        \n",
    "        if converted_stroke:  # Only add non-empty strokes\n",
    "            converted_strokes.append(converted_stroke)\n",
    "    \n",
    "    return converted_strokes\n",
    "\n",
    "\n",
    "def prepare_training_data(raw_data, max_seq_length=500):\n",
    "    \"\"\"\n",
    "    Prepare training data from HuggingFace dataset.\n",
    "    \n",
    "    Returns:\n",
    "        List of (strokes, text) tuples\n",
    "    \"\"\"\n",
    "    prepared_data = []\n",
    "    \n",
    "    for item in tqdm(raw_data, desc=\"Converting data\"):\n",
    "        text = item.get('text', '')\n",
    "        strokes = item.get('strokes', [])\n",
    "        canvas = item.get('canvas', {})\n",
    "        \n",
    "        # Get canvas dimensions if available\n",
    "        canvas_width = canvas.get('width') if isinstance(canvas, dict) else None\n",
    "        canvas_height = canvas.get('height') if isinstance(canvas, dict) else None\n",
    "        \n",
    "        # Convert strokes\n",
    "        converted_strokes = convert_hf_strokes_to_training_format(\n",
    "            strokes, canvas_width, canvas_height\n",
    "        )\n",
    "        \n",
    "        if converted_strokes and text:\n",
    "            # Check sequence length\n",
    "            total_points = sum(len(stroke) for stroke in converted_strokes)\n",
    "            if total_points <= max_seq_length:\n",
    "                prepared_data.append((converted_strokes, text))\n",
    "    \n",
    "    return prepared_data\n",
    "\n",
    "\n",
    "# Prepare the data\n",
    "print(\"Preparing training data...\")\n",
    "all_data = prepare_training_data(raw_data, config['max_seq_length'])\n",
    "print(f\"\\nPrepared {len(all_data)} valid samples\")\n",
    "\n",
    "# Show a sample\n",
    "if all_data:\n",
    "    sample_strokes, sample_text = all_data[0]\n",
    "    print(f\"\\nSample:\")\n",
    "    print(f\"  Text: '{sample_text}'\")\n",
    "    print(f\"  Number of strokes: {len(sample_strokes)}\")\n",
    "    print(f\"  Total points: {sum(len(s) for s in sample_strokes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and validation sets\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "# Shuffle the data\n",
    "shuffled_data = all_data.copy()\n",
    "random.shuffle(shuffled_data)\n",
    "\n",
    "# Split\n",
    "val_size = int(len(shuffled_data) * config['validation_split'])\n",
    "train_size = len(shuffled_data) - val_size\n",
    "\n",
    "train_data = shuffled_data[:train_size]\n",
    "val_data = shuffled_data[train_size:]\n",
    "\n",
    "print(f\"Training samples: {len(train_data)}\")\n",
    "print(f\"Validation samples: {len(val_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Build Character Set (Charset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build charset from training data\n",
    "def build_charset(data):\n",
    "    \"\"\"Build character set from the text data.\"\"\"\n",
    "    charset = set()\n",
    "    for _, text in data:\n",
    "        charset.update(set(text))\n",
    "    # Sort for consistency\n",
    "    return ''.join(sorted(charset))\n",
    "\n",
    "charset = build_charset(train_data)\n",
    "print(f\"Charset ({len(charset)} characters): '{charset}'\")\n",
    "\n",
    "# Create tokenizer\n",
    "tokenizer = Tokenizer(charset)\n",
    "print(f\"Tokenizer size (with padding): {tokenizer.size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create H5 Dataset Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data directory\n",
    "DATA_DIR = 'colab_data'\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "def preprocess_and_save_data(data_list, save_path, max_length):\n",
    "    \"\"\"\n",
    "    Preprocess data and save to H5 format.\n",
    "    \n",
    "    Preprocessing steps:\n",
    "    1. Flatten strokes into a list of (x, y, eos) points\n",
    "    2. Convert to offsets\n",
    "    3. Truncate if necessary\n",
    "    4. Save to H5 with computed mean and std\n",
    "    \"\"\"\n",
    "    processed = []\n",
    "    \n",
    "    for strokes, text in tqdm(data_list, desc=f\"Processing {os.path.basename(save_path)}\"):\n",
    "        # Flatten strokes to points\n",
    "        points = data.flatten_strokes(strokes)\n",
    "        # Convert to offsets\n",
    "        offsets = data.to_offsets(points)\n",
    "        # Truncate if needed\n",
    "        offsets = data.truncate_sequence(offsets, max_length)\n",
    "        \n",
    "        if offsets:\n",
    "            processed.append((offsets, text))\n",
    "    \n",
    "    # Save to H5\n",
    "    data.save_to_h5(processed, save_path, max_length)\n",
    "    \n",
    "    return len(processed)\n",
    "\n",
    "\n",
    "# Determine max sequence length from data\n",
    "max_lengths = []\n",
    "for strokes, _ in train_data:\n",
    "    points = data.flatten_strokes(strokes)\n",
    "    max_lengths.append(len(points))\n",
    "\n",
    "actual_max_length = max(max_lengths) if max_lengths else config['max_seq_length']\n",
    "max_length = min(actual_max_length, config['max_seq_length'])\n",
    "print(f\"Maximum sequence length in data: {actual_max_length}\")\n",
    "print(f\"Using max length: {max_length}\")\n",
    "\n",
    "# Process and save training data\n",
    "train_path = os.path.join(DATA_DIR, 'train.h5')\n",
    "num_train = preprocess_and_save_data(train_data, train_path, max_length)\n",
    "print(f\"Saved {num_train} training examples to {train_path}\")\n",
    "\n",
    "# Process and save validation data\n",
    "val_path = os.path.join(DATA_DIR, 'val.h5')\n",
    "num_val = preprocess_and_save_data(val_data, val_path, max_length)\n",
    "print(f\"Saved {num_val} validation examples to {val_path}\")\n",
    "\n",
    "# Save charset\n",
    "charset_path = os.path.join(DATA_DIR, 'charset.txt')\n",
    "tokenizer.save_charset(charset_path)\n",
    "print(f\"Saved charset to {charset_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Load Prepared Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the prepared datasets\n",
    "with data.H5Dataset(train_path) as train_h5:\n",
    "    mu = train_h5.mu\n",
    "    std = train_h5.std\n",
    "    dataset_max_length = train_h5.max_length\n",
    "\n",
    "print(f\"Dataset statistics:\")\n",
    "print(f\"  Mean (mu): {mu}\")\n",
    "print(f\"  Std: {std}\")\n",
    "print(f\"  Max length: {dataset_max_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Training Setup\n",
    "\n",
    "Set up the model, optimizer, and training components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create model\n",
    "alphabet_size = tokenizer.size\n",
    "model = models.SynthesisNetwork.get_default_model(alphabet_size, device)\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"\\nModel created:\")\n",
    "print(f\"  Alphabet size: {alphabet_size}\")\n",
    "print(f\"  Hidden size: {model.hidden_size}\")\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"  Total parameters: {total_params:,}\")\n",
    "print(f\"  Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthesizer for saving/loading\n",
    "mu_tensor = torch.tensor(mu, dtype=torch.float32)\n",
    "sd_tensor = torch.tensor(std, dtype=torch.float32)\n",
    "\n",
    "synthesizer = HandwritingSynthesizer(\n",
    "    model, mu_tensor, sd_tensor, charset, num_steps=dataset_max_length\n",
    ")\n",
    "\n",
    "# Create optimizer\n",
    "# Note: momentum=9000 is used as a flag to enable momentum buffer in CustomRMSprop.\n",
    "# The actual momentum decay is hardcoded to 0.9 in the optimizer implementation.\n",
    "# This follows the original training code from the repository.\n",
    "optimizer = CustomRMSprop(\n",
    "    model.parameters(),\n",
    "    lr=config['learning_rate'],\n",
    "    alpha=0.95,\n",
    "    eps=1e-4,\n",
    "    momentum=9000,\n",
    "    centered=True\n",
    ")\n",
    "\n",
    "# Gradient clipping values\n",
    "clip_output = config['gradient_clip_output']\n",
    "clip_lstm = config['gradient_clip_lstm']\n",
    "\n",
    "print(\"Optimizer and synthesizer created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Training Loop with tqdm and Sample Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    \"\"\"Collate function for DataLoader.\"\"\"\n",
    "    x, y = [], []\n",
    "    for points, text in batch:\n",
    "        x.append(points)\n",
    "        y.append(text)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def compute_loss(model, batch, tokenizer, device):\n",
    "    \"\"\"Compute loss for a batch.\"\"\"\n",
    "    points, transcriptions = batch\n",
    "    ground_true = utils.PaddedSequencesBatch(points, device=device)\n",
    "    \n",
    "    batch_size, steps, input_dim = ground_true.tensor.shape\n",
    "    \n",
    "    # Create input (shifted by one step)\n",
    "    prefix = torch.zeros(batch_size, 1, input_dim, device=device)\n",
    "    x = torch.cat([prefix, ground_true.tensor[:, :-1]], dim=1)\n",
    "    \n",
    "    # Create context (one-hot encoded transcriptions)\n",
    "    c = data.transcriptions_to_tensor(tokenizer, transcriptions).to(device)\n",
    "    \n",
    "    # Forward pass\n",
    "    mixtures, eos_hat = model(x, c)\n",
    "    \n",
    "    # Compute loss\n",
    "    loss = losses.nll_loss(mixtures, eos_hat, ground_true)\n",
    "    \n",
    "    return (mixtures, eos_hat), loss\n",
    "\n",
    "\n",
    "def generate_sample(model, tokenizer, mu, std, text, device, max_steps=500):\n",
    "    \"\"\"\n",
    "    Generate a handwriting sample for given text.\n",
    "    \n",
    "    Args:\n",
    "        model: The SynthesisNetwork model\n",
    "        tokenizer: Tokenizer for encoding text\n",
    "        mu: Mean values for denormalization (tuple)\n",
    "        std: Standard deviation values for denormalization (tuple)\n",
    "        text: Text to synthesize\n",
    "        device: PyTorch device\n",
    "        max_steps: Maximum number of points to generate\n",
    "    \n",
    "    Returns:\n",
    "        Tensor on CPU containing denormalized handwriting coordinates\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Encode text\n",
    "        sentinel = '\\n'\n",
    "        text_with_sentinel = text + sentinel\n",
    "        c = data.transcriptions_to_tensor(tokenizer, [text_with_sentinel]).to(device)\n",
    "        \n",
    "        # Generate\n",
    "        sample = model.sample_means(context=c, steps=max_steps, stochastic=True)\n",
    "        \n",
    "        # Denormalize and move to CPU\n",
    "        sample = sample.cpu() * torch.tensor(std) + torch.tensor(mu)\n",
    "        \n",
    "    model.train()\n",
    "    return sample\n",
    "\n",
    "\n",
    "def visualize_sample(sample, text, save_path=None):\n",
    "    \"\"\"Visualize a handwriting sample and display it.\"\"\"\n",
    "    # Use provided save_path or create a default one\n",
    "    if save_path is None:\n",
    "        save_path = os.path.join(SAMPLES_DIR, 'temp_sample.png')\n",
    "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        utils.visualize_strokes(sample, save_path, lines=True, thickness=8)\n",
    "        display(Image(filename=save_path))\n",
    "        print(f\"Text: '{text}'\")\n",
    "    except (IOError, ValueError, RuntimeError) as e:\n",
    "        print(f\"Could not visualize sample: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "EPOCHS = config['epochs']\n",
    "BATCH_SIZE = config['batch_size']\n",
    "SAMPLE_INTERVAL = config['sample_interval']  # Show samples every N epochs\n",
    "MODEL_SAVE_DIR = 'colab_checkpoints'\n",
    "SAMPLES_DIR = 'colab_samples'\n",
    "\n",
    "os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n",
    "os.makedirs(SAMPLES_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Training Configuration:\")\n",
    "print(f\"  Epochs: {EPOCHS}\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Sample every: {SAMPLE_INTERVAL} epochs\")\n",
    "print(f\"  Model save directory: {MODEL_SAVE_DIR}\")\n",
    "print(f\"  Samples directory: {SAMPLES_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Starting Training\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Training history\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# Initialize best_model_dir before training loop\n",
    "best_model_dir = os.path.join(MODEL_SAVE_DIR, 'best_model')\n",
    "\n",
    "# Open datasets\n",
    "train_dataset = data.NormalizedDataset(train_path, mu, std)\n",
    "val_dataset = data.NormalizedDataset(val_path, mu, std)\n",
    "\n",
    "# Validate datasets are not empty\n",
    "if len(train_dataset) == 0:\n",
    "    train_dataset.close()\n",
    "    val_dataset.close()\n",
    "    raise ValueError(\"Training dataset is empty! Please check your data preparation.\")\n",
    "\n",
    "if len(val_dataset) == 0:\n",
    "    print(\"Warning: Validation dataset is empty. Training will proceed without validation.\")\n",
    "\n",
    "# Get sample texts for visualization\n",
    "sample_texts = []\n",
    "for i in range(min(3, len(val_dataset))):\n",
    "    _, text = val_dataset[i]\n",
    "    sample_texts.append(text)\n",
    "\n",
    "print(f\"Sample texts for visualization: {sample_texts}\")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "num_train_batches = len(train_loader)\n",
    "num_val_batches = len(val_loader)\n",
    "\n",
    "print(f\"Training batches per epoch: {num_train_batches}\")\n",
    "print(f\"Validation batches per epoch: {num_val_batches}\")\n",
    "\n",
    "# Training\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "try:\n",
    "    epoch_pbar = tqdm(range(1, EPOCHS + 1), desc=\"Training\", unit=\"epoch\")\n",
    "\n",
    "    for epoch in epoch_pbar:\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        epoch_train_loss = 0.0\n",
    "        \n",
    "        batch_pbar = tqdm(train_loader, desc=f\"Epoch {epoch}/{EPOCHS}\", leave=False, unit=\"batch\")\n",
    "        \n",
    "        for batch_idx, batch in enumerate(batch_pbar):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Compute loss\n",
    "            y_hat, loss = compute_loss(model, batch, tokenizer, device)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            model.clip_gradients(output_clip_value=clip_output, lstm_clip_value=clip_lstm)\n",
    "            \n",
    "            # Update weights\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_train_loss += loss.item()\n",
    "            batch_pbar.set_postfix({'loss': f'{loss.item():.2f}'})\n",
    "        \n",
    "        avg_train_loss = epoch_train_loss / num_train_batches\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        epoch_val_loss = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                _, loss = compute_loss(model, batch, tokenizer, device)\n",
    "                epoch_val_loss += loss.item()\n",
    "        \n",
    "        avg_val_loss = epoch_val_loss / num_val_batches if num_val_batches > 0 else 0\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        # Update progress bar\n",
    "        epoch_pbar.set_postfix({\n",
    "            'train_loss': f'{avg_train_loss:.2f}',\n",
    "            'val_loss': f'{avg_val_loss:.2f}'\n",
    "        })\n",
    "        \n",
    "        # Save best model\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            synthesizer.save(best_model_dir)\n",
    "        \n",
    "        # Generate and display samples every SAMPLE_INTERVAL epochs\n",
    "        if epoch % SAMPLE_INTERVAL == 0:\n",
    "            print(f\"\\n\\n{'='*60}\")\n",
    "            print(f\"Epoch {epoch} - Sample Generation\")\n",
    "            print(f\"Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "            print(f\"{'='*60}\")\n",
    "            \n",
    "            for i, text in enumerate(sample_texts[:2]):  # Show 2 samples\n",
    "                sample = generate_sample(model, tokenizer, mu, std, text, device, dataset_max_length)\n",
    "                sample_path = os.path.join(SAMPLES_DIR, f'epoch_{epoch}_sample_{i}.png')\n",
    "                visualize_sample(sample, text, sample_path)\n",
    "            \n",
    "            print()\n",
    "        \n",
    "        # Save checkpoint every 20 epochs\n",
    "        if epoch % 20 == 0:\n",
    "            checkpoint_dir = os.path.join(MODEL_SAVE_DIR, f'Epoch_{epoch}')\n",
    "            synthesizer.save(checkpoint_dir)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Training Complete!\")\n",
    "    print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "finally:\n",
    "    # Always close datasets to prevent resource leaks\n",
    "    train_dataset.close()\n",
    "    val_dataset.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Training Results Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Loss plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Training Loss', color='blue', alpha=0.8)\n",
    "plt.plot(val_losses, label='Validation Loss', color='orange', alpha=0.8)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (nats)')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Smoothed loss plot\n",
    "plt.subplot(1, 2, 2)\n",
    "window = min(10, len(train_losses) // 4) if len(train_losses) > 4 else 1\n",
    "if window > 1:\n",
    "    train_smooth = np.convolve(train_losses, np.ones(window)/window, mode='valid')\n",
    "    val_smooth = np.convolve(val_losses, np.ones(window)/window, mode='valid')\n",
    "    plt.plot(range(window-1, len(train_losses)), train_smooth, label='Training (smoothed)', color='blue')\n",
    "    plt.plot(range(window-1, len(val_losses)), val_smooth, label='Validation (smoothed)', color='orange')\n",
    "else:\n",
    "    plt.plot(train_losses, label='Training Loss', color='blue')\n",
    "    plt.plot(val_losses, label='Validation Loss', color='orange')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (nats)')\n",
    "plt.title('Smoothed Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nFinal Training Loss: {train_losses[-1]:.4f}\")\n",
    "print(f\"Final Validation Loss: {val_losses[-1]:.4f}\")\n",
    "print(f\"Best Validation Loss: {best_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Generate Final Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "best_model_dir = os.path.join(MODEL_SAVE_DIR, 'best_model')\n",
    "best_synthesizer = HandwritingSynthesizer.load(best_model_dir, device, bias=1.0)\n",
    "\n",
    "print(\"Loaded best model for final samples\\n\")\n",
    "\n",
    "# Generate samples for all validation texts\n",
    "print(\"=\"*60)\n",
    "print(\"Final Generated Samples\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Reload validation data to get texts\n",
    "val_dataset = data.NormalizedDataset(val_path, mu, std)\n",
    "\n",
    "for i in range(min(5, len(val_dataset))):\n",
    "    _, text = val_dataset[i]\n",
    "    \n",
    "    print(f\"\\nSample {i+1}: '{text}'\")\n",
    "    \n",
    "    sample = generate_sample(\n",
    "        best_synthesizer.model, \n",
    "        tokenizer, \n",
    "        mu, std, \n",
    "        text, \n",
    "        device, \n",
    "        dataset_max_length\n",
    "    )\n",
    "    \n",
    "    sample_path = os.path.join(SAMPLES_DIR, f'final_sample_{i}.png')\n",
    "    visualize_sample(sample, text, sample_path)\n",
    "\n",
    "val_dataset.close()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"All samples generated!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Save Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final model\n",
    "final_model_dir = os.path.join(MODEL_SAVE_DIR, 'final_model')\n",
    "synthesizer.save(final_model_dir)\n",
    "\n",
    "print(f\"Final model saved to: {final_model_dir}\")\n",
    "print(f\"Best model saved to: {best_model_dir}\")\n",
    "\n",
    "# List all saved files\n",
    "print(f\"\\nSaved model files:\")\n",
    "for root, dirs, files in os.walk(MODEL_SAVE_DIR):\n",
    "    level = root.replace(MODEL_SAVE_DIR, '').count(os.sep)\n",
    "    indent = ' ' * 2 * level\n",
    "    print(f\"{indent}{os.path.basename(root)}/\")\n",
    "    subindent = ' ' * 2 * (level + 1)\n",
    "    for file in files:\n",
    "        print(f\"{subindent}{file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Download Model (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip the models for download\n",
    "import shutil\n",
    "\n",
    "# Create zip archive\n",
    "shutil.make_archive('handwriting_model', 'zip', MODEL_SAVE_DIR)\n",
    "\n",
    "print(\"Model archive created: handwriting_model.zip\")\n",
    "print(\"\\nTo download, click on the file in the file browser (left sidebar) and download.\")\n",
    "\n",
    "# For Google Colab - download directly\n",
    "try:\n",
    "    from google.colab import files\n",
    "    files.download('handwriting_model.zip')\n",
    "except ImportError:\n",
    "    print(\"Not running in Google Colab - manual download required.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Interactive Synthesis (Optional)\n",
    "\n",
    "Use this cell to generate handwriting for custom text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom text synthesis\n",
    "CUSTOM_TEXT = \"Hallo\"  # Change this to your desired text\n",
    "\n",
    "print(f\"Generating handwriting for: '{CUSTOM_TEXT}'\")\n",
    "\n",
    "# Check if all characters are in charset\n",
    "missing_chars = set(CUSTOM_TEXT) - set(charset)\n",
    "if missing_chars:\n",
    "    print(f\"Warning: Characters not in charset: {missing_chars}\")\n",
    "    print(f\"Available characters: '{charset}'\")\n",
    "else:\n",
    "    # Use best_synthesizer if available, otherwise fall back to model\n",
    "    synthesis_model = best_synthesizer.model if 'best_synthesizer' in dir() and best_synthesizer is not None else model\n",
    "    \n",
    "    sample = generate_sample(\n",
    "        synthesis_model,\n",
    "        tokenizer,\n",
    "        mu, std,\n",
    "        CUSTOM_TEXT,\n",
    "        device,\n",
    "        dataset_max_length\n",
    "    )\n",
    "    \n",
    "    custom_path = os.path.join(SAMPLES_DIR, 'custom_sample.png')\n",
    "    visualize_sample(sample, CUSTOM_TEXT, custom_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Training Summary\n",
    "\n",
    "This notebook trained a handwriting synthesis model using:\n",
    "\n",
    "- **Dataset**: HuggingFace dataset `finnbusse/v3testing`\n",
    "- **Model**: SynthesisNetwork based on Alex Graves' paper \"Generating Sequences With Recurrent Neural Networks\"\n",
    "- **Architecture**: 3-layer LSTM with soft attention window mechanism\n",
    "\n",
    "### Hyperparameters Used\n",
    "- Batch size: {config['batch_size']}\n",
    "- Epochs: {config['epochs']}\n",
    "- Learning rate: {config['learning_rate']}\n",
    "- Hidden size: {config['hidden_size']}\n",
    "- Gradient clipping: {config['gradient_clip_output']} (output), {config['gradient_clip_lstm']} (LSTM)\n",
    "\n",
    "### Tips for Better Results\n",
    "1. **More data**: Collect more handwriting samples for better generalization\n",
    "2. **Longer training**: Increase epochs if validation loss is still decreasing\n",
    "3. **Data augmentation**: Add slight variations to stroke data\n",
    "4. **Probability bias**: Use bias parameter when generating samples for cleaner output"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
